AWSTemplateFormatVersion: '2010-09-09'
Description: Combined CloudFormation template to create S3 buckets and AWS Glue jobs/workflows

Parameters:
  DataLakeBucket:
    Type: String
    Description: "The S3 bucket for the data lake"
  DataWarehouseBucket:
    Type: String
    Description: "The S3 bucket for the data warehouse"
  ScriptBucket:
    Type: String
    Description: "The S3 bucket where the Glue scripts are stored"
  GlueRoleArn:
    Type: String
    Description: "The ARN of the IAM role for AWS Glue"

Conditions:
  CreateDataLakeBucket: !Equals 
    - !Ref DataLakeBucket
    - ''
  CreateDataWarehouseBucket: !Equals 
    - !Ref DataWarehouseBucket
    - ''

Resources:
  MyS3Bucket1:
    Type: AWS::S3::Bucket
    Condition: CreateDataLakeBucket
    Properties:
      BucketName: !Ref DataLakeBucket
      VersioningConfiguration:
        Status: Suspended
      Tags:
        - Key: Name
          Value: group5-1

  MyS3Bucket2:
    Type: AWS::S3::Bucket
    Condition: CreateDataWarehouseBucket
    Properties:
      BucketName: !Ref DataWarehouseBucket
      VersioningConfiguration:
        Status: Suspended
      Tags:
        - Key: Name
          Value: group5-2

  DataOpsGlueIngestionJob:
    Type: AWS::Glue::Job
    Properties:
      Name: "dataops-glue-ingestion-job"
      Role: !Ref GlueRoleArn
      Command:
        Name: "glueetl"
        ScriptLocation: !Sub "s3://${ScriptBucket}/script-ingestion/ingestion.py"
        PythonVersion: "3"
      GlueVersion: "4.0"
      NumberOfWorkers: 10
      WorkerType: "G.1X"

  DataOpsGluePreProcessingJob:
    Type: AWS::Glue::Job
    Properties:
      Name: "dataops-glue-preprocessing-job"
      Role: !Ref GlueRoleArn
      Command:
        Name: "glueetl"
        ScriptLocation: !Sub "s3://${ScriptBucket}/script-pre-processing/pre_processing.py"
        PythonVersion: "3"
      GlueVersion: "4.0"
      NumberOfWorkers: 10
      WorkerType: "G.1X"
      DefaultArguments:
        '--TempDir': !Sub "s3://${DataLakeBucket}-temp/temp/"
        '--job-language': 'python'

  DataOpsGlueWorkflow:
    Type: AWS::Glue::Workflow
    Properties:
      Name: "dataops-glue-workflow"
      Description: "Workflow to orchestrate ingestion and preprocessing jobs"

  DataOpsWorkflowStartTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: "dataops-workflow-start-trigger"
      Type: ON_DEMAND
      Description: "Trigger to start the workflow"
      Actions:
        - JobName: !Ref DataOpsGlueIngestionJob
      WorkflowName: !Ref DataOpsGlueWorkflow

  DataOpsIngestionToPreProcessingTrigger:
    Type: AWS::Glue::Trigger
    DependsOn:
      - DataOpsGlueIngestionJob
      - DataOpsGluePreProcessingJob
    Properties:
      Name: "dataops-glue-trigger-ingestion-to-preprocessing"
      Description: "Trigger to start preprocessing job after ingestion job completes"
      Type: CONDITIONAL
      StartOnCreation: true
      Actions:
        - JobName: !Ref DataOpsGluePreProcessingJob
      Predicate:
        Conditions:
          - JobName: !Ref DataOpsGlueIngestionJob
            LogicalOperator: EQUALS
            State: SUCCEEDED
      WorkflowName: !Ref DataOpsGlueWorkflow

Outputs:
  DataLakeBucketName:
    Description: 'Name of the Data Lake S3 Bucket'
    Value: !Ref MyS3Bucket1
  DataWarehouseBucketName:
    Description: 'Name of the Data Warehouse S3 Bucket'
    Value: !Ref MyS3Bucket2
  PreProcessingJobName:
    Description: 'Name of the Glue Pre-Processing Job'
    Value: !Ref DataOpsGluePreProcessingJob
  WorkflowName:
    Description: 'Name of the Glue Workflow'
    Value: !Ref DataOpsGlueWorkflow
  StartTriggerName:
    Description: 'Name of the Workflow Start Trigger'
    Value: !Ref DataOpsWorkflowStartTrigger
